{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M-Qp4n4gYDsX"
      },
      "outputs": [],
      "source": [
        "#! pip install google-generativeai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nqnrzMCZjpt7",
        "outputId": "0b8b3416-bca5-4e34-c8f7-f72f227e2757"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "e:\\Program Files\\Anaconda\\envs\\cuda310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "from PIL import Image\n",
        "import google.generativeai as genai\n",
        "import os\n",
        "import shutil\n",
        "import time\n",
        "import re\n",
        "import csv\n",
        "\n",
        "# Gemini API config\n",
        "genai.configure(api_key=\"YOUR API KEY\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''For using this notebook recreate the following structure\n",
        "\n",
        "parent_dir\n",
        "-\n",
        "-- noclass_memes --> memes to be classified\n",
        "-\n",
        "--new_hate_speech\n",
        "-\n",
        "--new_inappropiate_content\n",
        "-\n",
        "--new_none\n",
        "-\n",
        "--new_dataset.csv --> outcome dataset'''\n",
        "\n",
        "# Defining directories\n",
        "parent_dir = # insert here your parent directory\n",
        "noclass_memes = parent_dir + \"noclass_memes/\"\n",
        "hs_path = parent_dir + \"new_hate_speech/\"\n",
        "ic_path = parent_dir + \"new_inappropiate_content/\"\n",
        "none_path = parent_dir + \"new_none/\"\n",
        "new_dataset_path = parent_dir + \"new_dataset.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "gQQpzclbgHr7"
      },
      "outputs": [],
      "source": [
        "# Setting up the model\n",
        "generation_config = {\n",
        "  \"temperature\": 1,\n",
        "  \"top_p\": 0.95,\n",
        "  \"top_k\": 0,\n",
        "  \"max_output_tokens\": 8192\n",
        "}\n",
        "\n",
        "safety_settings = [\n",
        "  {\n",
        "    \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
        "    \"threshold\": \"BLOCK_NONE\"\n",
        "  },\n",
        "  {\n",
        "    \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
        "    \"threshold\": \"BLOCK_NONE\"\n",
        "  },\n",
        "  {\n",
        "    \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
        "    \"threshold\": \"BLOCK_NONE\"\n",
        "  },\n",
        "  {\n",
        "    \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
        "    \"threshold\": \"BLOCK_NONE\"\n",
        "  },\n",
        "]\n",
        "\n",
        "system_instruction = \"You are going to be provided with an image of a meme in spanish and you will be performing three different tasks:\\n1. Indicate if the meme is written in English or Spanish in bold\\n2. You will need to extract the text of the meme like an OCR, displaying it in an appropiate format for storing it in a database (without newlines, in a sentence). The output for this task will be displayed in the following format: /*HERE GOES THE MEME TEXT*/\\n3. You will be performing two classification sub-tasks:\\n   A) The first task will be clasifying the meme between the three following categories:\\n\\t- hate_speech: this category will be composed by memes that contain racism, classism, sexism or other.\\n\\t- inappropiate_content: this category will contain memes that are inappropiate but do not contain hate speech.\\n\\t- none: this category will be composed by memes that do not belong to the other categories, memes that you do not understand, memes in a language that is not spanish or any other image that is not a meme.\\n   B) The second task will be a finer-grain classification performed only for the memes considered as hate_speech in the previous task, the classes are the following:\\n\\t- racism: category containing racist memes.\\n\\t- classism: category containing classist memes.\\n\\t- sexism: category containing sexist memes.\\n\\t- other: category containing other type of hate speech memes.\\nYou can develop your explanations for the classification, but you should always specify the categories in the following format only at the end of the explanation: ||CATEGORY TASK A||\\t&&CATEGORY TASK B&&\\nUnder no circumstances you could classify a racist, classist, sexist or other hate speech meme as inappropiate content. Ensure you are correctly following all the output formats specified.\\n\"\n",
        "\n",
        "model = genai.GenerativeModel(model_name=\"models/gemini-1.5-pro-latest\",\n",
        "                              generation_config=generation_config,\n",
        "                              safety_settings=safety_settings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "**Spanish**\n",
            "/*Parece ser que la cerveza contiene hormonas femeninas despu√©s de beber suficiente, no sabes conducir, ni puedes parar de hablar*/ \n",
            "\n",
            "This meme implies that women talk a lot and cannot drive, perpetuating harmful stereotypes. ||hate_speech|| &&sexism&& \n",
            "\n",
            "**English**\n",
            "\n",
            "/*I AM BLACK AND I WAS THE PRESIDENT OF THE USA, YOU LOOSER*/\n",
            "\n",
            "The meme makes a statement about Barack Obama's presidency and his race, but it does not express hate or discrimination towards any specific group. The use of the word \"looser\" (misspelled) could be considered offensive, but it's used in a context of rivalry or competition, not to promote hate. \n",
            "\n",
            "||none|| &&N/A&& \n",
            "\n"
          ]
        }
      ],
      "source": [
        "index = 1\n",
        "trash_index = 1\n",
        "\n",
        "with open(new_dataset_path, \"a\", newline=\"\") as file:\n",
        "    reader = csv.writer(file)\n",
        "    for filename in os.listdir(noclass_memes):\n",
        "        if filename.endswith('.jpg'):  # Filter by extension\n",
        "            # Load image\n",
        "            img_path = os.path.join(noclass_memes, filename)\n",
        "            img = Image.open(img_path)\n",
        "            try:\n",
        "                # Obtain model output\n",
        "                response = model.generate_content([system_instruction,img], stream=False)\n",
        "                response.resolve()\n",
        "                output = response.text\n",
        "                print(output)\n",
        "                \n",
        "                # Check if the meme is English or Spanish\n",
        "                language = re.search(r'\\*\\*(.*?)\\*\\*', output).group(1)     # **LANGUAGE**\n",
        "                if language == \"English\":\n",
        "                    label_1 = \"none\"\n",
        "                else:\n",
        "                    # If Spanish extract text and first label\n",
        "                    meme_text = re.search(r'/\\*(.*?)\\*/', output).group(1)      # /*IMG TEXT*/ \n",
        "                    label_1 = re.search(r'\\|\\|(.*?)\\|\\|', output).group(1)      # ||LABEL_1||\n",
        "\n",
        "                # Moving the image to its corresponding directory \n",
        "                if label_1 == \"hate_speech\":\n",
        "                    label_2 = re.search(r'&&([^&]*)&&', output).group(1)        # &&LABEL_2&&\n",
        "                    img_dest_path = hs_path + label_2 + \"/NEW_IMG_\" + str(index) + \".jpg\"\n",
        "                    # Create csv entry\n",
        "                    reader.writerow([\"NEW_IMG_\" + str(index), meme_text, label_1, label_2])\n",
        "                    index+=1\n",
        "                elif label_1 == \"inappropiate_content\":\n",
        "                    img_dest_path = ic_path + \"/NEW_IMG_\" + str(index) + \".jpg\"\n",
        "                    # Create csv entry\n",
        "                    reader.writerow([\"NEW_IMG_\" + str(index), meme_text, label_1, label_1])\n",
        "                    index+=1\n",
        "                else:\n",
        "                    img_dest_path = none_path + \"/NEW_IMG_\"+ str(trash_index) + \".jpg\"\n",
        "                    trash_index+=1\n",
        "                shutil.move(img_path, img_dest_path)\n",
        "            except:\n",
        "                print(\"API FAILURE\")\n",
        "            time.sleep(20)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
